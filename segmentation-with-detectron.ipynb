{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport json\nimport os\nimport random\nimport cv2\n\nprint(f\"pandas version: {pd.__version__}\")\nprint(f\"numpy version: {np.__version__}\")","metadata":{"execution":{"iopub.status.busy":"2022-11-30T13:37:43.248632Z","iopub.execute_input":"2022-11-30T13:37:43.248954Z","iopub.status.idle":"2022-11-30T13:37:43.440710Z","shell.execute_reply.started":"2022-11-30T13:37:43.248879Z","shell.execute_reply":"2022-11-30T13:37:43.439707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training dataset\ntrain_df = pd.read_csv('/kaggle/input/imaterialist-fashion-2020-fgvc7/train.csv')\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T13:38:10.052531Z","iopub.execute_input":"2022-11-30T13:38:10.052891Z","iopub.status.idle":"2022-11-30T13:38:42.128146Z","shell.execute_reply.started":"2022-11-30T13:38:10.052860Z","shell.execute_reply":"2022-11-30T13:38:42.127256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get datasets shapes\nprint(f'Training dataset shape: {train_df.shape}')\nprint(f'Unique images training: {train_df[\"ImageId\"].nunique()}')","metadata":{"execution":{"iopub.status.busy":"2022-11-29T13:52:28.759035Z","iopub.execute_input":"2022-11-29T13:52:28.759405Z","iopub.status.idle":"2022-11-29T13:52:28.814620Z","shell.execute_reply.started":"2022-11-29T13:52:28.759365Z","shell.execute_reply":"2022-11-29T13:52:28.813245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get image size distribution\nshape_df = train_df.groupby(\"ImageId\")[[\"Height\", \"Width\"]].first()\nfor dim in [\"Height\", \"Width\"]:\n    plt.figure()\n    plt.hist(shape_df[dim], bins=50)\n    plt.grid()\n    plt.title(f\"{dim} distribution\")","metadata":{"execution":{"iopub.status.busy":"2022-11-29T13:52:37.182860Z","iopub.execute_input":"2022-11-29T13:52:37.183223Z","iopub.status.idle":"2022-11-29T13:52:37.929228Z","shell.execute_reply.started":"2022-11-29T13:52:37.183193Z","shell.execute_reply":"2022-11-29T13:52:37.928156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot randomly selected image\nplt.figure(figsize=(70,7))\nrandom_image = train_df.sample()[\"ImageId\"].item()\nplt.imshow(mpimg.imread(f'/kaggle/input/imaterialist-fashion-2020-fgvc7/train/{random_image}.jpg'))\nplt.grid(False)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-29T13:52:41.732150Z","iopub.execute_input":"2022-11-29T13:52:41.732669Z","iopub.status.idle":"2022-11-29T13:52:42.118932Z","shell.execute_reply.started":"2022-11-29T13:52:41.732624Z","shell.execute_reply":"2022-11-29T13:52:42.117574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get label file\nwith open('/kaggle/input/imaterialist-fashion-2020-fgvc7/label_descriptions.json', 'r') as file:\n    label_d = json.load(file)\n\nprint(\"Label description columns {}\".format(list(label_d.keys())))","metadata":{"execution":{"iopub.status.busy":"2022-11-30T13:39:01.335602Z","iopub.execute_input":"2022-11-30T13:39:01.336427Z","iopub.status.idle":"2022-11-30T13:39:01.349755Z","shell.execute_reply.started":"2022-11-30T13:39:01.336389Z","shell.execute_reply":"2022-11-30T13:39:01.348416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Separate label description into categories and attributes\ncategories_df = pd.DataFrame(label_d['categories'])\nattributes_df = pd.DataFrame(label_d['attributes'])","metadata":{"execution":{"iopub.status.busy":"2022-11-30T13:39:04.528460Z","iopub.execute_input":"2022-11-30T13:39:04.529071Z","iopub.status.idle":"2022-11-30T13:39:04.539579Z","shell.execute_reply.started":"2022-11-30T13:39:04.529024Z","shell.execute_reply":"2022-11-30T13:39:04.538172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categories_df","metadata":{"execution":{"iopub.status.busy":"2022-11-29T13:52:12.435379Z","iopub.execute_input":"2022-11-29T13:52:12.436074Z","iopub.status.idle":"2022-11-29T13:52:12.453356Z","shell.execute_reply.started":"2022-11-29T13:52:12.436036Z","shell.execute_reply":"2022-11-29T13:52:12.452258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# make all categories stored by one variables\ncateg_names = categories_df[\"name\"].unique()\nprint(categ_names)\nprint(f\"Number of attributes {len(categ_names)}\")","metadata":{"execution":{"iopub.status.busy":"2022-11-30T13:39:08.552276Z","iopub.execute_input":"2022-11-30T13:39:08.552827Z","iopub.status.idle":"2022-11-30T13:39:08.566464Z","shell.execute_reply.started":"2022-11-30T13:39:08.552785Z","shell.execute_reply":"2022-11-30T13:39:08.565357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# make all attributes stored by one variables\nattr_names = attributes_df[\"name\"].unique()\nprint(attr_names)\nprint(f\"Number of attributes {len(attr_names)}\")","metadata":{"execution":{"iopub.status.busy":"2022-11-30T13:39:10.856931Z","iopub.execute_input":"2022-11-30T13:39:10.857304Z","iopub.status.idle":"2022-11-30T13:39:10.865586Z","shell.execute_reply.started":"2022-11-30T13:39:10.857273Z","shell.execute_reply":"2022-11-30T13:39:10.864474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create dictionaries to map the IDs with the category and attributes strings\ncat_map = {category[\"id\"]: category[\"name\"] for category in label_d['categories']}\ncat_map_inv = {category[\"name\"]: category[\"id\"] for category in label_d['categories']}\n\nattr_map = {category[\"id\"]: category[\"name\"] for category in label_d['attributes']}\nattr_map_inv = {category[\"name\"]: category[\"id\"] for category in label_d['attributes']}","metadata":{"execution":{"iopub.status.busy":"2022-11-30T13:39:14.336378Z","iopub.execute_input":"2022-11-30T13:39:14.336735Z","iopub.status.idle":"2022-11-30T13:39:14.343047Z","shell.execute_reply.started":"2022-11-30T13:39:14.336699Z","shell.execute_reply":"2022-11-30T13:39:14.341660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_map","metadata":{"execution":{"iopub.status.busy":"2022-11-29T13:52:57.658596Z","iopub.execute_input":"2022-11-29T13:52:57.658977Z","iopub.status.idle":"2022-11-29T13:52:57.667577Z","shell.execute_reply.started":"2022-11-29T13:52:57.658943Z","shell.execute_reply":"2022-11-29T13:52:57.666591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plot segmented images","metadata":{}},{"cell_type":"code","source":"def plot_raw_segmented_image(df, figsize=(15,15)):\n    # Read random image\n    random_id = df.sample()[\"ImageId\"].item()\n    image = mpimg.imread(f'/kaggle/input/imaterialist-fashion-2020-fgvc7/train/{random_id}.jpg')\n    shape = image.shape,\n    encoded_pixels = df[train_df['ImageId'] == random_id]['EncodedPixels']\n    class_ids = df[train_df['ImageId'] == random_id]['ClassId']\n    \n    # Create mask\n    height, width = shape[0][:2]\n    mask = np.zeros((height, width)).reshape(-1)\n    for pixels, class_id in zip(encoded_pixels, class_ids):\n        pixels_split = list(map(int, pixels.split()))\n        pixel_starts = pixels_split[::2]\n        run_lengths = pixels_split[1::2]\n        for pixel_start, run_length in zip(pixel_starts, run_lengths):\n            mask[pixel_start:pixel_start + run_length] = 255 - int(class_id) * 4\n    mask = mask.reshape(height, width, order='F')    \n    \n    # Plot images\n    fig, axs = plt.subplots(1, 2,figsize=(15,15))\n    axs[0].imshow(image)    \n    axs[1].imshow(image)    \n    axs[1].imshow(mask, alpha=0.8)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T13:39:18.236998Z","iopub.execute_input":"2022-11-30T13:39:18.237661Z","iopub.status.idle":"2022-11-30T13:39:18.247365Z","shell.execute_reply.started":"2022-11-30T13:39:18.237625Z","shell.execute_reply":"2022-11-30T13:39:18.246407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot raw and segmented images\nsize = 3\nfor _ in range(size):\n    plot_raw_segmented_image(train_df, \"ImageId\")","metadata":{"execution":{"iopub.status.busy":"2022-11-29T13:53:06.302659Z","iopub.execute_input":"2022-11-29T13:53:06.303034Z","iopub.status.idle":"2022-11-29T13:53:13.059448Z","shell.execute_reply.started":"2022-11-29T13:53:06.303003Z","shell.execute_reply":"2022-11-29T13:53:13.058558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_classes_image(df, figsize=(15,15)):\n    # Select random image\n    random_id = df.sample()[\"ImageId\"].item()\n    image = mpimg.imread(f'/kaggle/input/imaterialist-fashion-2020-fgvc7/train/{random_id}.jpg')\n    shape = image.shape,\n    encoded_pixels = df[train_df['ImageId'] == random_id]['EncodedPixels']\n    class_ids = df[train_df['ImageId'] == random_id]['ClassId']\n    \n    # Create mask and plot every specific class in the image\n    height, width = shape[0][:2]\n    for pixels, class_id in zip(encoded_pixels, class_ids):\n        mask = np.zeros((height, width)).reshape(-1)\n        pixels_split = list(map(int, pixels.split()))\n        pixel_starts = pixels_split[::2]\n        run_lengths = pixels_split[1::2]\n        for pixel_start, run_length in zip(pixel_starts, run_lengths):\n            mask[pixel_start:pixel_start + run_length] = 255 - int(class_id) * 4\n        mask = mask.reshape(height, width, order='F')\n        \n        # Plot masked image\n        plt.figure(figsize=(15, 15))\n        title_raw = cat_map[int(class_id)]\n        plt.title(title_raw)\n        plt.imshow(image)    \n        plt.imshow(mask, alpha=0.8)\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T13:39:24.223149Z","iopub.execute_input":"2022-11-30T13:39:24.223508Z","iopub.status.idle":"2022-11-30T13:39:24.235915Z","shell.execute_reply.started":"2022-11-30T13:39:24.223477Z","shell.execute_reply":"2022-11-30T13:39:24.234767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_classes_image(train_df)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T13:53:33.399219Z","iopub.execute_input":"2022-11-29T13:53:33.399615Z","iopub.status.idle":"2022-11-29T13:53:54.830273Z","shell.execute_reply.started":"2022-11-29T13:53:33.399581Z","shell.execute_reply":"2022-11-29T13:53:54.829391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Detectron","metadata":{}},{"cell_type":"code","source":"!pip install -q cython pyyaml","metadata":{"execution":{"iopub.status.busy":"2022-11-30T13:39:34.842614Z","iopub.execute_input":"2022-11-30T13:39:34.842981Z","iopub.status.idle":"2022-11-30T13:39:45.844175Z","shell.execute_reply.started":"2022-11-30T13:39:34.842948Z","shell.execute_reply":"2022-11-30T13:39:45.843017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install pycocotools==2.0.2","metadata":{"execution":{"iopub.status.busy":"2022-11-30T13:39:51.929645Z","iopub.execute_input":"2022-11-30T13:39:51.930028Z","iopub.status.idle":"2022-11-30T13:40:09.822237Z","shell.execute_reply.started":"2022-11-30T13:39:51.929993Z","shell.execute_reply":"2022-11-30T13:40:09.820726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install 'git+https://github.com/facebookresearch/detectron2.git'","metadata":{"execution":{"iopub.status.busy":"2022-11-30T13:40:19.563338Z","iopub.execute_input":"2022-11-30T13:40:19.563722Z","iopub.status.idle":"2022-11-30T13:43:05.814784Z","shell.execute_reply.started":"2022-11-30T13:40:19.563684Z","shell.execute_reply":"2022-11-30T13:43:05.813579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Make libraries","metadata":{}},{"cell_type":"code","source":"from detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer\nfrom detectron2.data import MetadataCatalog, DatasetCatalog\nfrom detectron2.structures import BoxMode","metadata":{"execution":{"iopub.status.busy":"2022-11-30T13:43:27.296219Z","iopub.execute_input":"2022-11-30T13:43:27.296625Z","iopub.status.idle":"2022-11-30T13:43:29.346242Z","shell.execute_reply.started":"2022-11-30T13:43:27.296588Z","shell.execute_reply":"2022-11-30T13:43:29.345044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Use detectron in current dataset","metadata":{}},{"cell_type":"code","source":"!pip install torch","metadata":{"execution":{"iopub.status.busy":"2022-11-24T10:46:31.160374Z","iopub.execute_input":"2022-11-24T10:46:31.160921Z","iopub.status.idle":"2022-11-24T10:46:43.085151Z","shell.execute_reply.started":"2022-11-24T10:46:31.160874Z","shell.execute_reply":"2022-11-24T10:46:43.083458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\ntorch.cuda.is_available()","metadata":{"execution":{"iopub.status.busy":"2022-11-24T10:46:46.589835Z","iopub.execute_input":"2022-11-24T10:46:46.590875Z","iopub.status.idle":"2022-11-24T10:46:46.601343Z","shell.execute_reply.started":"2022-11-24T10:46:46.590820Z","shell.execute_reply":"2022-11-24T10:46:46.599647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python -m torch.utils.collect_env","metadata":{"execution":{"iopub.status.busy":"2022-11-24T10:47:49.148491Z","iopub.execute_input":"2022-11-24T10:47:49.148989Z","iopub.status.idle":"2022-11-24T10:48:15.291194Z","shell.execute_reply.started":"2022-11-24T10:47:49.148950Z","shell.execute_reply":"2022-11-24T10:48:15.289575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use detectron to predict images in the current dataset,\n# use the default weights and labels from the network\nconfig_file = \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"\ncfg = get_cfg()\ncfg.merge_from_file(model_zoo.get_config_file(config_file))\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(config_file)\n\npredictor = DefaultPredictor(cfg)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T13:59:31.394700Z","iopub.execute_input":"2022-11-29T13:59:31.396064Z","iopub.status.idle":"2022-11-29T13:59:40.569549Z","shell.execute_reply.started":"2022-11-29T13:59:31.396019Z","shell.execute_reply":"2022-11-29T13:59:40.568560Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot images classified by the pretrained detectron\nrows, cols = 2, 2\nplt.figure(figsize=(20, 20))\n\nfor i in range(int(rows * cols)):\n    plt.subplot(rows, cols, i + 1)\n    \n    # Get random image\n    random_id = train_df.sample()[\"ImageId\"].item()\n    im = mpimg.imread(f'/kaggle/input/imaterialist-fashion-2020-fgvc7/train/{random_id}.jpg')\n    height, width = im.shape[:2]\n    \n    # Get detectron prediction from the selected image\n    outputs = predictor(im)\n    \n    # Create visualizer\n    visualizer = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=0.4)\n    \n    # Change font size for better reading\n    visualizer._default_font_size = np.sqrt(height * width) // 20\n    visualizer = visualizer.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n    \n    # Plot images\n    plt.axis('off')\n    plt.imshow(visualizer.get_image()[:, :, ::-1])\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-29T13:59:47.389048Z","iopub.execute_input":"2022-11-29T13:59:47.389462Z","iopub.status.idle":"2022-11-29T13:59:59.986053Z","shell.execute_reply.started":"2022-11-29T13:59:47.389426Z","shell.execute_reply":"2022-11-29T13:59:59.984923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Add Details","metadata":{}},{"cell_type":"code","source":"def rle_decode_string(string, h, w):\n    \"\"\"\n    Transforms rle string into a pixel mask\n    \n    :param string: rle string to transform into mask\n    :type string: str\n    :param string: image height\n    :type string: int\n    :param string: image width\n    :type string: int\n    :return: image mask\n    :rtype: numpy array\n\n    \"\"\"\n    mask = np.full(h * w, 0, dtype=np.uint8)\n    annotation = [int(x) for x in string.split(' ')]\n    for i, start_pixel in enumerate(annotation[::2]):\n        mask[start_pixel: start_pixel + annotation[2 * i + 1]] = 1\n    mask = mask.reshape((h, w), order='F')\n    return mask\n\ndef rle2bbox(rle, shape):\n    '''\n    Get a bbox from a mask which is required for Detectron 2 dataset\n    :param rle: run-length encoded image mask, as string\n    :type rle: str\n    :param shape: (height, width) of image on which RLE was produced\n    :type rle: tuple\n    :return: (x0, y0, x1, y1) tuple describing the bounding box of the rle mask\n    :rtype: tuple\n    '''\n    \n    a = np.fromiter(rle.split(), dtype=np.uint)\n    a = a.reshape((-1, 2))  # an array of (start, length) pairs\n    a[:,0] -= 1  # `start` is 1-indexed\n    \n    y0 = a[:,0] % shape[0]\n    y1 = y0 + a[:,1]\n    if np.any(y1 > shape[0]):\n        # got `y` overrun, meaning that there are a pixels in mask on 0 and shape[0] position\n        y0 = 0\n        y1 = shape[0]\n    else:\n        y0 = np.min(y0)\n        y1 = np.max(y1)\n    \n    x0 = a[:,0] // shape[0]\n    x1 = (a[:,0] + a[:,1]) // shape[0]\n    x0 = np.min(x0)\n    x1 = np.max(x1)\n    \n    if x1 > shape[1]:\n        # just went out of the image dimensions\n        raise ValueError(\"invalid RLE or image dimensions: x1=%d > shape[1]=%d\" % (\n            x1, shape[1]\n        ))\n\n    return x0, y0, x1, y1","metadata":{"execution":{"iopub.status.busy":"2022-11-30T13:43:35.689331Z","iopub.execute_input":"2022-11-30T13:43:35.689946Z","iopub.status.idle":"2022-11-30T13:43:35.702517Z","shell.execute_reply.started":"2022-11-30T13:43:35.689910Z","shell.execute_reply":"2022-11-30T13:43:35.701466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Transform ImageId into image path\nimage_dir = '/kaggle/input/imaterialist-fashion-2020-fgvc7/train/'\ntrain_df['ImageId'] = image_dir + train_df['ImageId'] + '.jpg'\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T13:43:40.014628Z","iopub.execute_input":"2022-11-30T13:43:40.014999Z","iopub.status.idle":"2022-11-30T13:43:40.161035Z","shell.execute_reply.started":"2022-11-30T13:43:40.014966Z","shell.execute_reply":"2022-11-30T13:43:40.160090Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['ImageId'][40]","metadata":{"execution":{"iopub.status.busy":"2022-11-30T13:43:47.775613Z","iopub.execute_input":"2022-11-30T13:43:47.776048Z","iopub.status.idle":"2022-11-30T13:43:47.782718Z","shell.execute_reply.started":"2022-11-30T13:43:47.776013Z","shell.execute_reply":"2022-11-30T13:43:47.781770Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create boxes list\nbboxes = [rle2bbox(c.EncodedPixels, (c.Height, c.Width)) for n, c in train_df.iterrows()]\nbboxes_array = np.array(bboxes)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T13:43:51.064322Z","iopub.execute_input":"2022-11-30T13:43:51.064765Z","iopub.status.idle":"2022-11-30T13:45:16.013136Z","shell.execute_reply.started":"2022-11-30T13:43:51.064724Z","shell.execute_reply":"2022-11-30T13:45:16.011972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fill NaNs\ntrain_df = train_df.fillna(999)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T13:45:37.649088Z","iopub.execute_input":"2022-11-30T13:45:37.649837Z","iopub.status.idle":"2022-11-30T13:45:37.759248Z","shell.execute_reply.started":"2022-11-30T13:45:37.649799Z","shell.execute_reply":"2022-11-30T13:45:37.758368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add bounding boxes coordinates to train using detectron\ntrain_df['x0'], train_df['y0'], train_df['x1'], train_df['y1'] = bboxes_array[:,0], bboxes_array[:,1], bboxes_array[:,2], bboxes_array[:,3]\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T13:45:40.866797Z","iopub.execute_input":"2022-11-30T13:45:40.867232Z","iopub.status.idle":"2022-11-30T13:45:40.894440Z","shell.execute_reply.started":"2022-11-30T13:45:40.867136Z","shell.execute_reply":"2022-11-30T13:45:40.893371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def transform_to_array(value):\n    if isinstance(value, (np.ndarray, np.generic)):\n        return value\n    elif isinstance(value, str):\n        array = [int(val) for val in value.split(\",\")]\n    elif isinstance(value, int):\n        array = [999] \n    array = np.array(array)\n    return np.pad(array, (0, 14 - len(array)))","metadata":{"execution":{"iopub.status.busy":"2022-11-30T13:45:44.222046Z","iopub.execute_input":"2022-11-30T13:45:44.222434Z","iopub.status.idle":"2022-11-30T13:45:44.229572Z","shell.execute_reply.started":"2022-11-30T13:45:44.222403Z","shell.execute_reply":"2022-11-30T13:45:44.228393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Transform attribute string into tensor\ntrain_df[\"AttributesIds\"] = train_df[\"AttributesIds\"].map(transform_to_array)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T13:45:48.496647Z","iopub.execute_input":"2022-11-30T13:45:48.497015Z","iopub.status.idle":"2022-11-30T13:45:56.574131Z","shell.execute_reply.started":"2022-11-30T13:45:48.496982Z","shell.execute_reply":"2022-11-30T13:45:56.573151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['ImageId'][100]","metadata":{"execution":{"iopub.status.busy":"2022-11-29T10:37:12.562750Z","iopub.execute_input":"2022-11-29T10:37:12.563106Z","iopub.status.idle":"2022-11-29T10:37:12.569905Z","shell.execute_reply.started":"2022-11-29T10:37:12.563077Z","shell.execute_reply":"2022-11-29T10:37:12.568851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Store modified train_df\ntrain_df.to_pickle(\"train_df.pickle\")","metadata":{"execution":{"iopub.status.busy":"2022-11-30T13:46:06.920520Z","iopub.execute_input":"2022-11-30T13:46:06.920886Z","iopub.status.idle":"2022-11-30T13:46:10.987804Z","shell.execute_reply.started":"2022-11-30T13:46:06.920857Z","shell.execute_reply":"2022-11-30T13:46:10.986715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train_df))","metadata":{"execution":{"iopub.status.busy":"2022-11-30T13:46:25.238093Z","iopub.execute_input":"2022-11-30T13:46:25.238572Z","iopub.status.idle":"2022-11-30T13:46:25.245142Z","shell.execute_reply.started":"2022-11-30T13:46:25.238537Z","shell.execute_reply":"2022-11-30T13:46:25.244146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Get data to train","metadata":{}},{"cell_type":"code","source":"import pycocotools\ndef get_materialist_dicts(df):\n    \"\"\"\n    Transforms dataframe into dictionary used to train using detectron\n    \"\"\"\n    dataset_dicts = []\n    for idx, filename in enumerate(df[\"ImageId\"].unique()):\n        record = {}\n        # Get useful image information\n        height, width = df[df[\"ImageId\"] == filename][[\"Height\", \"Width\"]].values[0]\n        record[\"file_name\"] = filename\n        record[\"image_id\"] = idx\n        record[\"height\"] = int(height)\n        record[\"width\"] = int(width)\n        \n        if idx % 1000 == 0:\n            print(idx)\n        \n        objs = []\n        for i, row in df[(df['ImageId'] == filename)].iterrows():\n            \n            # Get segmentation polygons\n            mask = rle_decode_string(row['EncodedPixels'], row['Height'], row['Width'])\n            # segmentation = pycocotools.mask.encode(np.asarray(mask, order=\"F\"))\n            contours, hierarchy = cv2.findContours((mask).astype(np.uint8), cv2.RETR_TREE,\n                                                    cv2.CHAIN_APPROX_SIMPLE)\n            segmentation = []\n\n            for contour in contours:\n                contour = contour.flatten().tolist()\n                if len(contour) > 4:\n                    segmentation.append(contour)\n\n            obj = {\n                \"bbox\": [row['x0'], row['y0'], row['x1'], row['y1']],\n                \"bbox_mode\": BoxMode.XYXY_ABS,\n                \"segmentation\": segmentation,\n                \"category_id\": row['ClassId'],\n                \"attributes\": row['AttributesIds'],\n                \"iscrowd\": 0,\n            }\n            objs.append(obj)\n        \n        record['annotations'] = objs\n        dataset_dicts.append(record)\n    return dataset_dicts\n\n# Use reduced dictionary to reduce the time to transform into dictionaries\n#df_copy = train_df[:8000].copy()\n\ndf_copy = train_df.copy()\n\ndf_copy = train_df[:23000].copy()\ndf_copy_val = train_df[23000:24000].copy()\n\n# Full dictionary\n# df_copy = train_df.copy()\n\nmaterialist_dict = get_materialist_dicts(df_copy)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T13:46:28.202161Z","iopub.execute_input":"2022-11-30T13:46:28.202537Z","iopub.status.idle":"2022-11-30T13:53:32.645945Z","shell.execute_reply.started":"2022-11-30T13:46:28.202504Z","shell.execute_reply":"2022-11-30T13:53:32.644812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"materialist_dict[0].keys()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T13:53:55.582037Z","iopub.execute_input":"2022-11-30T13:53:55.582437Z","iopub.status.idle":"2022-11-30T13:53:55.588957Z","shell.execute_reply.started":"2022-11-30T13:53:55.582405Z","shell.execute_reply":"2022-11-30T13:53:55.588008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(df_copy))\nprint(len(df_copy_val))\nprint(len(materialist_dict))\nprint(len(train_df))\nprint(len(train_df[\"ImageId\"].unique()))\nprint(len(df_copy[\"ImageId\"].unique()))","metadata":{"execution":{"iopub.status.busy":"2022-11-30T13:53:58.515901Z","iopub.execute_input":"2022-11-30T13:53:58.516343Z","iopub.status.idle":"2022-11-30T13:53:58.599006Z","shell.execute_reply.started":"2022-11-30T13:53:58.516310Z","shell.execute_reply":"2022-11-30T13:53:58.597860Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Register the custom dataset to detectron2,\nfor d in [\"train\", \"val\"]:\n    if d == \"train\":\n        used_df = df_copy\n    else:\n        used_df = df_copy_val\n    DatasetCatalog.register(\"mat_\" + d, lambda df=used_df: get_materialist_dicts(df))\n    # DatasetCatalog.register(\"mat_\" + d, lambda df=df_copy: get_materialist_dicts(df))\n    MetadataCatalog.get(\"mat_\" + d).set(thing_classes=list(categories_df.name))\nmaterialist_metadata = MetadataCatalog.get(\"mat_train\")","metadata":{"execution":{"iopub.status.busy":"2022-11-30T13:54:01.291771Z","iopub.execute_input":"2022-11-30T13:54:01.292130Z","iopub.status.idle":"2022-11-30T13:54:01.298857Z","shell.execute_reply.started":"2022-11-30T13:54:01.292085Z","shell.execute_reply":"2022-11-30T13:54:01.297900Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To verify the data loading is correct we visualize the annotations of randomly selected samples in the training set\nfor d in random.sample(materialist_dict, 5):\n    img = cv2.imread(d[\"file_name\"])\n    img = mpimg.imread(d[\"file_name\"])\n    height, width = img.shape[:2]\n    plt.figure(figsize=(20, 20))\n    visualizer = Visualizer(img[:, :, ::-1], metadata=materialist_metadata, scale=0.5)\n    visualizer._default_font_size = np.sqrt(height * width) // 20\n    out = visualizer.draw_dataset_dict(d)\n    plt.imshow(out.get_image()[:, :, ::-1])\n    plt.axis('off')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T13:54:04.287561Z","iopub.execute_input":"2022-11-30T13:54:04.287931Z","iopub.status.idle":"2022-11-30T13:54:11.729978Z","shell.execute_reply.started":"2022-11-30T13:54:04.287900Z","shell.execute_reply":"2022-11-30T13:54:11.729136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare to train","metadata":{}},{"cell_type":"code","source":"logdir = \"logs\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_callback = tensorflow.keras.callbacks.TensorBoard(log_dir=logdir)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load extension tensorboard\n%load_ext tensorboard\n%tensorboard  --logdir output","metadata":{"execution":{"iopub.status.busy":"2022-11-25T15:36:26.271520Z","iopub.execute_input":"2022-11-25T15:36:26.271907Z","iopub.status.idle":"2022-11-25T15:36:26.278487Z","shell.execute_reply.started":"2022-11-25T15:36:26.271875Z","shell.execute_reply":"2022-11-25T15:36:26.277061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%tensorboard  --logdir=(logdir)","metadata":{"execution":{"iopub.status.busy":"2022-11-25T15:45:07.149185Z","iopub.execute_input":"2022-11-25T15:45:07.150440Z","iopub.status.idle":"2022-11-25T15:45:11.751297Z","shell.execute_reply.started":"2022-11-25T15:45:07.150389Z","shell.execute_reply":"2022-11-25T15:45:11.750112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# FPN","metadata":{}},{"cell_type":"code","source":"from detectron2.utils.logger import setup_logger\nsetup_logger()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T13:54:37.189332Z","iopub.execute_input":"2022-11-30T13:54:37.189732Z","iopub.status.idle":"2022-11-30T13:54:37.196294Z","shell.execute_reply.started":"2022-11-30T13:54:37.189702Z","shell.execute_reply":"2022-11-30T13:54:37.195311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from detectron2.engine import DefaultTrainer\nos.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n\n# Fine-tune a COCO-pretrained R50-FPN Mask R-CNN model on the dataset\ncfg_FPN = get_cfg()\ncfg_FPN.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\ncfg_FPN.DATASETS.TRAIN = (\"mat_train\",)\ncfg_FPN.DATASETS.TEST = (\"mat_val\",)\ncfg_FPN.DATALOADER.NUM_WORKERS = 1\ncfg_FPN.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\ncfg_FPN.SOLVER.IMS_PER_BATCH = 2\ncfg_FPN.SOLVER.BASE_LR = 0.00025 \ncfg_FPN.SOLVER.MAX_ITER = 1000  \ncfg_FPN.SOLVER.STEPS = []       \ncfg_FPN.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128  \ncfg_FPN.MODEL.ROI_HEADS.NUM_CLASSES = 46 \n\n# Train\ncfg_FPN.OUTPUT_DIR = \"./output_FPN\"\nos.makedirs(cfg_FPN.OUTPUT_DIR, exist_ok=True)\ntrainer_FPN = DefaultTrainer(cfg_FPN) \ntrainer_FPN.resume_or_load(resume=False)\ntrainer_FPN.train()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T13:54:46.882298Z","iopub.execute_input":"2022-11-30T13:54:46.882649Z","iopub.status.idle":"2022-11-30T14:15:40.570999Z","shell.execute_reply.started":"2022-11-30T13:54:46.882620Z","shell.execute_reply":"2022-11-30T14:15:40.569735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create predictor from the weigths obtained during the training\ncfg_FPN.MODEL.WEIGHTS = os.path.join(cfg_FPN.OUTPUT_DIR, \"model_final.pth\")\ncfg_FPN.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set the testing threshold for this model\ncfg_FPN.DATASETS.TEST = ('mat_val',)\npredictor_FPN = DefaultPredictor(cfg_FPN)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T14:16:18.412792Z","iopub.execute_input":"2022-11-30T14:16:18.413279Z","iopub.status.idle":"2022-11-30T14:16:19.751657Z","shell.execute_reply.started":"2022-11-30T14:16:18.413228Z","shell.execute_reply":"2022-11-30T14:16:19.750640Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%reload_ext tensorboard\n\n%tensorboard --logdir output --bind_all","metadata":{"execution":{"iopub.status.busy":"2022-11-30T14:54:30.683242Z","iopub.execute_input":"2022-11-30T14:54:30.683758Z","iopub.status.idle":"2022-11-30T14:54:34.425134Z","shell.execute_reply.started":"2022-11-30T14:54:30.683708Z","shell.execute_reply":"2022-11-30T14:54:34.424018Z"},"trusted":true},"execution_count":42,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n      <iframe id=\"tensorboard-frame-8e271fe6613fd094\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-8e271fe6613fd094\");\n          const url = new URL(\"/\", window.location);\n          const port = 6007;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "},"metadata":{}}]},{"cell_type":"code","source":"from detectron2.utils.visualizer import ColorMode\nplt.figure(figsize=(20,20))\nfor d in random.sample(materialist_dict, 3):    \n    im = cv2.imread(d[\"file_name\"])\n    outputs = predictor_FPN(im)\n    visualizer = Visualizer(im[:, :, ::-1],\n                   metadata=materialist_metadata, \n                   scale=0.8, \n                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n    )\n    v = visualizer.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n    plt.imshow(v.get_image()[:, :, ::-1])","metadata":{"execution":{"iopub.status.busy":"2022-11-30T14:16:35.024656Z","iopub.execute_input":"2022-11-30T14:16:35.025057Z","iopub.status.idle":"2022-11-30T14:16:51.669471Z","shell.execute_reply.started":"2022-11-30T14:16:35.025025Z","shell.execute_reply":"2022-11-30T14:16:51.668368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from detectron2.utils.visualizer import ColorMode\n\n# Show different images at random\nrows, cols = 3, 3\nplt.figure(figsize=(20,20))\n\nfor i, d in enumerate(random.sample(materialist_dict, 9)):\n    # Process image\n    plt.subplot(rows, cols, i+1)\n\n    im = cv2.imread(d[\"file_name\"])\n    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n    \n    # Run through predictor\n    outputs = predictor_FPN(im)\n    \n    # Visualize\n    v = Visualizer(im[:, :, ::-1],\n                   metadata=materialist_metadata, \n                   scale=0.8, \n                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n    )\n    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n    plt.imshow(v.get_image()[:, :, ::-1])\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T14:16:51.671500Z","iopub.execute_input":"2022-11-30T14:16:51.671849Z","iopub.status.idle":"2022-11-30T14:17:13.701796Z","shell.execute_reply.started":"2022-11-30T14:16:51.671817Z","shell.execute_reply":"2022-11-30T14:17:13.700732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from detectron2.evaluation import COCOEvaluator, inference_on_dataset\nfrom detectron2.data import build_detection_test_loader\n\n# Evaluate model\nevaluator_FPN = COCOEvaluator(\"mat_val\", output_dir=\"./output\")\nval_loader_FPN = build_detection_test_loader(cfg_FPN, \"mat_val\")","metadata":{"execution":{"iopub.status.busy":"2022-11-30T14:18:49.157155Z","iopub.execute_input":"2022-11-30T14:18:49.158194Z","iopub.status.idle":"2022-11-30T14:19:40.490195Z","shell.execute_reply.started":"2022-11-30T14:18:49.158110Z","shell.execute_reply":"2022-11-30T14:19:40.489086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get results\nresult_FPN = inference_on_dataset(predictor_FPN.model, val_loader_FPN, evaluator_FPN)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T14:21:42.425218Z","iopub.execute_input":"2022-11-30T14:21:42.425854Z","iopub.status.idle":"2022-11-30T14:22:40.540803Z","shell.execute_reply.started":"2022-11-30T14:21:42.425816Z","shell.execute_reply":"2022-11-30T14:22:40.539788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_FPN","metadata":{"execution":{"iopub.status.busy":"2022-11-30T14:24:17.025299Z","iopub.execute_input":"2022-11-30T14:24:17.025710Z","iopub.status.idle":"2022-11-30T14:24:17.035808Z","shell.execute_reply.started":"2022-11-30T14:24:17.025673Z","shell.execute_reply":"2022-11-30T14:24:17.034712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_FPN = OrderedDict([('bbox',\n              {'AP': 4.042041386236529,\n               'AP50': 7.009528515579133,\n               'AP75': 4.272181159399969,\n               'APs': 2.8642149929278644,\n               'APm': 4.436359715472674,\n               'APl': 4.175886251256949,\n               'AP-shirt, blouse': 0.0,\n               'AP-top, t-shirt, sweatshirt': 3.6115040075436116,\n               'AP-sweater': 0.0,\n               'AP-cardigan': 0.0,\n               'AP-jacket': 0.0,\n               'AP-vest': 0.0,\n               'AP-pants': 22.712319374254037,\n               'AP-shorts': 0.0,\n               'AP-skirt': 0.0,\n               'AP-coat': 0.0,\n               'AP-dress': 36.79138174864801,\n               'AP-jumpsuit': 0.0,\n               'AP-cape': 0.0,\n               'AP-glasses': 0.0,\n               'AP-hat': 0.0,\n               'AP-headband, head covering, hair accessory': 0.0,\n               'AP-tie': 0.0,\n               'AP-glove': 0.0,\n               'AP-watch': 0.0,\n               'AP-belt': 0.0,\n               'AP-leg warmer': -1,\n               'AP-tights, stockings': 0.0,\n               'AP-sock': 0.0,\n               'AP-shoe': 42.691991932292986,\n               'AP-bag, wallet': 0.0,\n               'AP-scarf': 0.0,\n               'AP-umbrella': -1,\n               'AP-hood': 0.0,\n               'AP-collar': 8.310573351834575,\n               'AP-lapel': 0.0,\n               'AP-epaulette': 0.0,\n               'AP-sleeve': 36.739201247615455,\n               'AP-pocket': 0.0,\n               'AP-neckline': 6.782642401035951,\n               'AP-buckle': 0.0,\n               'AP-zipper': 0.0,\n               'AP-applique': 0.0,\n               'AP-bead': 0.0,\n               'AP-bow': 0.0,\n               'AP-flower': -1,\n               'AP-fringe': -1,\n               'AP-ribbon': -1,\n               'AP-rivet': 0.0,\n               'AP-ruffle': 0.0,\n               'AP-sequin': -1,\n               'AP-tassel': -1}),\n             ('segm',\n              {'AP': 3.4087200430046565,\n               'AP50': 5.657970853825233,\n               'AP75': 3.6954433313462216,\n               'APs': 0.3951495149514952,\n               'APm': 2.1513857128643084,\n               'APl': 3.9158018526800653,\n               'AP-shirt, blouse': 0.0,\n               'AP-top, t-shirt, sweatshirt': 4.867986798679868,\n               'AP-sweater': 0.0,\n               'AP-cardigan': 0.0,\n               'AP-jacket': 0.0,\n               'AP-vest': 0.0,\n               'AP-pants': 29.593245025414213,\n               'AP-shorts': 0.0,\n               'AP-skirt': 0.0,\n               'AP-coat': 0.0,\n               'AP-dress': 39.42114295317396,\n               'AP-jumpsuit': 0.0,\n               'AP-cape': 0.0,\n               'AP-glasses': 0.0,\n               'AP-hat': 0.0,\n               'AP-headband, head covering, hair accessory': 0.0,\n               'AP-tie': 0.0,\n               'AP-glove': 0.0,\n               'AP-watch': 0.0,\n               'AP-belt': 0.0,\n               'AP-leg warmer': -1,\n               'AP-tights, stockings': 0.0,\n               'AP-sock': 0.0,\n               'AP-shoe': 21.30350902783804,\n               'AP-bag, wallet': 0.0,\n               'AP-scarf': 0.0,\n               'AP-umbrella': -1,\n               'AP-hood': 0.0,\n               'AP-collar': 0.19393233440991156,\n               'AP-lapel': 0.0,\n               'AP-epaulette': 0.0,\n               'AP-sleeve': 37.558015312643114,\n               'AP-pocket': 0.0,\n               'AP-neckline': 0.0022502250225022503,\n               'AP-buckle': 0.0,\n               'AP-zipper': 0.0,\n               'AP-applique': 0.0,\n               'AP-bead': 0.0,\n               'AP-bow': 0.0,\n               'AP-flower': -1,\n               'AP-fringe': -1,\n               'AP-ribbon': -1,\n               'AP-rivet': 0.0,\n               'AP-ruffle': 0.0,\n               'AP-sequin': -1,\n               'AP-tassel': -1})])","metadata":{"execution":{"iopub.status.busy":"2022-11-29T11:17:06.276884Z","iopub.execute_input":"2022-11-29T11:17:06.277467Z","iopub.status.idle":"2022-11-29T11:17:06.628034Z","shell.execute_reply.started":"2022-11-29T11:17:06.277429Z","shell.execute_reply":"2022-11-29T11:17:06.626535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DC5","metadata":{}},{"cell_type":"code","source":"from detectron2.engine import DefaultTrainer\nos.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n\n# Fine-tune a COCO-pretrained R50-DC5 Mask R-CNN model on the dataset\ncfg_DC5 = get_cfg()\ncfg_DC5.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_DC5_3x.yaml\"))\ncfg_DC5.DATASETS.TRAIN = (\"mat_train\",)\ncfg_DC5.DATASETS.TEST = ()\ncfg_DC5.DATALOADER.NUM_WORKERS = 1\ncfg_DC5.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_DC5_3x.yaml\")\ncfg_DC5.SOLVER.IMS_PER_BATCH = 2\ncfg_DC5.SOLVER.BASE_LR = 0.00025  \ncfg_DC5.SOLVER.MAX_ITER = 1000\ncfg_DC5.SOLVER.STEPS = []    \ncfg_DC5.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128  \ncfg_DC5.MODEL.ROI_HEADS.NUM_CLASSES = 46  \n\n# Train\ncfg_DC5.OUTPUT_DIR = \"./output_DC5\"\nos.makedirs(cfg_DC5.OUTPUT_DIR, exist_ok=True)\ntrainer_DC5 = DefaultTrainer(cfg_DC5) \ntrainer_DC5.resume_or_load(resume=False)\ntrainer_DC5.train()","metadata":{"execution":{"iopub.status.busy":"2022-11-29T14:13:06.852051Z","iopub.execute_input":"2022-11-29T14:13:06.852419Z","iopub.status.idle":"2022-11-29T14:40:15.564301Z","shell.execute_reply.started":"2022-11-29T14:13:06.852387Z","shell.execute_reply":"2022-11-29T14:40:15.562968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg_DC5.MODEL.WEIGHTS = os.path.join(cfg_DC5.OUTPUT_DIR, \"model_final.pth\")\ncfg_DC5.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set the testing threshold for this model\ncfg_DC5.DATASETS.TEST = ('mat_val')\npredictor_DC5 = DefaultPredictor(cfg_DC5)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T14:41:18.031236Z","iopub.execute_input":"2022-11-29T14:41:18.032648Z","iopub.status.idle":"2022-11-29T14:41:22.253194Z","shell.execute_reply.started":"2022-11-29T14:41:18.032587Z","shell.execute_reply":"2022-11-29T14:41:22.252151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load extension tensorboard\n%load_ext tensorboard\n%tensorboard  --logdir output","metadata":{"execution":{"iopub.status.busy":"2022-11-30T14:25:07.036684Z","iopub.execute_input":"2022-11-30T14:25:07.037142Z","iopub.status.idle":"2022-11-30T14:25:11.778276Z","shell.execute_reply.started":"2022-11-30T14:25:07.037089Z","shell.execute_reply":"2022-11-30T14:25:11.777163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from detectron2.utils.visualizer import ColorMode\nplt.figure(figsize=(20,20))\nfor d in random.sample(materialist_dict, 3):    \n    im = cv2.imread(d[\"file_name\"])\n    outputs = predictor_DC5(im)\n    visualizer = Visualizer(im[:, :, ::-1],\n                   metadata=materialist_metadata, \n                   scale=0.8, \n                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n    )\n    v = visualizer.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n    plt.imshow(v.get_image()[:, :, ::-1])","metadata":{"execution":{"iopub.status.busy":"2022-11-29T14:41:46.018133Z","iopub.execute_input":"2022-11-29T14:41:46.018551Z","iopub.status.idle":"2022-11-29T14:41:49.783460Z","shell.execute_reply.started":"2022-11-29T14:41:46.018498Z","shell.execute_reply":"2022-11-29T14:41:49.782429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Show different images at random\nrows, cols = 3, 3\nplt.figure(figsize=(20,20))\nfor i, d in enumerate(random.sample(materialist_dict, 9)):\n    # Process image\n    plt.subplot(rows, cols, i+1)\n    im = cv2.imread(d[\"file_name\"])\n    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n    \n    # Run through predictor\n    outputs = predictor_DC5(im)\n    \n    # Visualize\n    v = Visualizer(im[:, :, ::-1],\n                   metadata=materialist_metadata, \n                   scale=0.8, \n                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n    )\n    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n    plt.imshow(v.get_image()[:, :, ::-1])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-29T14:48:20.288461Z","iopub.execute_input":"2022-11-29T14:48:20.289298Z","iopub.status.idle":"2022-11-29T14:48:43.255387Z","shell.execute_reply.started":"2022-11-29T14:48:20.289255Z","shell.execute_reply":"2022-11-29T14:48:43.254457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from detectron2.evaluation import COCOEvaluator, inference_on_dataset\nfrom detectron2.data import build_detection_test_loader\n\n# Evaluate model\nevaluator_DC5 = COCOEvaluator(\"mat_val\", output_dir=cfg_DC5.OUTPUT_DIR)\nval_loader_DC5 = build_detection_test_loader(cfg_DC5, \"mat_val\")\nresult_DC5 = inference_on_dataset(predictor_DC5.model, val_loader_DC5, evaluator_DC5)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T14:49:59.470496Z","iopub.execute_input":"2022-11-29T14:49:59.471105Z","iopub.status.idle":"2022-11-29T14:51:36.103622Z","shell.execute_reply.started":"2022-11-29T14:49:59.471049Z","shell.execute_reply":"2022-11-29T14:51:36.102557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_DC5","metadata":{"execution":{"iopub.status.busy":"2022-11-29T08:16:00.122838Z","iopub.execute_input":"2022-11-29T08:16:00.123248Z","iopub.status.idle":"2022-11-29T08:16:00.132973Z","shell.execute_reply.started":"2022-11-29T08:16:00.123215Z","shell.execute_reply":"2022-11-29T08:16:00.132039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import collections \nresult_DC5 = collections.OrderedDict([('bbox',\n              {'AP': 4.525191941379816,\n               'AP50': 7.861780384443219,\n               'AP75': 4.962870113473836,\n               'APs': 2.690041468669624,\n               'APm': 4.381724195462682,\n               'APl': 4.9131784577118465,\n               'AP-shirt, blouse': 0.0,\n               'AP-top, t-shirt, sweatshirt': 9.08129251254038,\n               'AP-sweater': 0.0,\n               'AP-cardigan': 0.0,\n               'AP-jacket': 0.0,\n               'AP-vest': 0.0,\n               'AP-pants': 28.77881395602568,\n               'AP-shorts': 0.0,\n               'AP-skirt': 0.0,\n               'AP-coat': 0.0,\n               'AP-dress': 36.62626955070075,\n               'AP-jumpsuit': 0.0,\n               'AP-cape': 0.0,\n               'AP-glasses': 0.0,\n               'AP-hat': 0.0,\n               'AP-headband, head covering, hair accessory': 0.0,\n               'AP-tie': 0.0,\n               'AP-glove': 0.0,\n               'AP-watch': 0.0,\n               'AP-belt': 0.0,\n               'AP-leg warmer': -1,\n               'AP-tights, stockings': 0.0,\n               'AP-sock': 0.0,\n               'AP-shoe': 44.286675073755184,\n               'AP-bag, wallet': 5.346534653465347,\n               'AP-scarf': 0.0,\n               'AP-umbrella': -1,\n               'AP-hood': 0.0,\n               'AP-collar': 0.39603960396039606,\n               'AP-lapel': 0.0,\n               'AP-epaulette': 0.0,\n               'AP-sleeve': 43.18201285462164,\n               'AP-pocket': 0.0,\n               'AP-neckline': 8.784847508743479,\n               'AP-buckle': 0.0,\n               'AP-zipper': 0.0,\n               'AP-applique': 0.0,\n               'AP-bead': 0.0,\n               'AP-bow': 0.0,\n               'AP-flower': -1,\n               'AP-fringe': -1,\n               'AP-ribbon': -1,\n               'AP-rivet': 0.0,\n               'AP-ruffle': 0.0,\n               'AP-sequin': -1,\n               'AP-tassel': -1}),\n             ('segm',\n              {'AP': 4.148658488100851,\n               'AP50': 6.764338958984722,\n               'AP75': 4.433934143648775,\n               'APs': 0.3431447100754031,\n               'APm': 2.57813452468239,\n               'APl': 4.882275533962463,\n               'AP-shirt, blouse': 0.0,\n               'AP-top, t-shirt, sweatshirt': 11.4868204327064,\n               'AP-sweater': 0.0,\n               'AP-cardigan': 0.0,\n               'AP-jacket': 0.0,\n               'AP-vest': 0.0,\n               'AP-pants': 31.72714711007093,\n               'AP-shorts': 0.0,\n               'AP-skirt': 0.0,\n               'AP-coat': 0.0,\n               'AP-dress': 46.916030506073156,\n               'AP-jumpsuit': 0.0,\n               'AP-cape': 0.0,\n               'AP-glasses': 0.0,\n               'AP-hat': 0.0,\n               'AP-headband, head covering, hair accessory': 0.0,\n               'AP-tie': 0.0,\n               'AP-glove': 0.0,\n               'AP-watch': 0.0,\n               'AP-belt': 0.0,\n               'AP-leg warmer': -1,\n               'AP-tights, stockings': 0.0,\n               'AP-sock': 0.0,\n               'AP-shoe': 23.737265884581422,\n               'AP-bag, wallet': 4.158415841584159,\n               'AP-scarf': 0.0,\n               'AP-umbrella': -1,\n               'AP-hood': 0.0,\n               'AP-collar': 0.132013201320132,\n               'AP-lapel': 0.0,\n               'AP-epaulette': 0.0,\n               'AP-sleeve': 43.63807009106468,\n               'AP-pocket': 0.0,\n               'AP-neckline': 0.0019179685323128938,\n               'AP-buckle': 0.0,\n               'AP-zipper': 0.0,\n               'AP-applique': 0.0,\n               'AP-bead': 0.0,\n               'AP-bow': 0.0,\n               'AP-flower': -1,\n               'AP-fringe': -1,\n               'AP-ribbon': -1,\n               'AP-rivet': -1,\n               'AP-ruffle': 0.0,\n               'AP-sequin': -1,\n               'AP-tassel': -1})])","metadata":{"execution":{"iopub.status.busy":"2022-11-29T10:00:33.433536Z","iopub.execute_input":"2022-11-29T10:00:33.433935Z","iopub.status.idle":"2022-11-29T10:00:33.447982Z","shell.execute_reply.started":"2022-11-29T10:00:33.433898Z","shell.execute_reply":"2022-11-29T10:00:33.446958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# C4","metadata":{}},{"cell_type":"code","source":"from detectron2.engine import DefaultTrainer\n\n# Fine-tune a COCO-pretrained R50-C4 Mask R-CNN model on the dataset\ncfg_C4 = get_cfg()\ncfg_C4.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_C4_3x.yaml\"))\ncfg_C4.DATASETS.TRAIN = (\"mat_train\",)\ncfg_C4.DATASETS.TEST = ()\ncfg_C4.DATALOADER.NUM_WORKERS = 2\ncfg_C4.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_C4_3x.yaml\")\ncfg_C4.SOLVER.IMS_PER_BATCH = 2\ncfg_C4.SOLVER.BASE_LR = 0.00025\ncfg_C4.SOLVER.MAX_ITER = 1000\ncfg_C4.SOLVER.STEPS = []\ncfg_C4.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\ncfg_C4.MODEL.ROI_HEADS.NUM_CLASSES = 46\n\n# Train\ncfg_C4.OUTPUT_DIR = \"./output_C4\"\nos.makedirs(cfg_C4.OUTPUT_DIR, exist_ok=True)\ntrainer_C4 = DefaultTrainer(cfg_C4) \ntrainer_C4.resume_or_load(resume=False)\ntrainer_C4.train()","metadata":{"execution":{"iopub.status.busy":"2022-11-29T09:23:50.595496Z","iopub.execute_input":"2022-11-29T09:23:50.595892Z","iopub.status.idle":"2022-11-29T09:43:20.306928Z","shell.execute_reply.started":"2022-11-29T09:23:50.595859Z","shell.execute_reply":"2022-11-29T09:43:20.305627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create predictor from the weigths obtained during the training\ncfg_C4.MODEL.WEIGHTS = os.path.join(cfg_C4.OUTPUT_DIR, \"model_final.pth\")\ncfg_C4.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\ncfg_C4.DATASETS.TEST = ('mat_val')\npredictor_C4 = DefaultPredictor(cfg_C4)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T09:44:54.565038Z","iopub.execute_input":"2022-11-29T09:44:54.565485Z","iopub.status.idle":"2022-11-29T09:44:55.858737Z","shell.execute_reply.started":"2022-11-29T09:44:54.565445Z","shell.execute_reply":"2022-11-29T09:44:55.857816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from detectron2.utils.visualizer import ColorMode\nplt.figure(figsize=(20,20))\nfor d in random.sample(materialist_dict, 3):    \n    im = cv2.imread(d[\"file_name\"])\n    outputs = predictor_C4(im)\n    visualizer = Visualizer(im[:, :, ::-1],\n                   metadata=materialist_metadata, \n                   scale=0.8, \n                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n    )\n    v = visualizer.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n    plt.imshow(v.get_image()[:, :, ::-1])","metadata":{"execution":{"iopub.status.busy":"2022-11-29T09:45:05.595514Z","iopub.execute_input":"2022-11-29T09:45:05.595915Z","iopub.status.idle":"2022-11-29T09:45:09.246002Z","shell.execute_reply.started":"2022-11-29T09:45:05.595880Z","shell.execute_reply":"2022-11-29T09:45:09.244881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Show different images at random\nrows, cols = 3, 3\nplt.figure(figsize=(20,20))\nfor i, d in enumerate(random.sample(materialist_dict, 9)):\n    # Process image\n    plt.subplot(rows, cols, i+1)\n    im = cv2.imread(d[\"file_name\"])\n    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n    \n    # Run through predictor\n    outputs = predictor_C4(im)\n    \n    # Visualize\n    v = Visualizer(im[:, :, ::-1],\n                   metadata=materialist_metadata, \n                   scale=0.8, \n                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n    )\n    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n    plt.imshow(v.get_image()[:, :, ::-1])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-29T09:45:51.120356Z","iopub.execute_input":"2022-11-29T09:45:51.121775Z","iopub.status.idle":"2022-11-29T09:46:14.102452Z","shell.execute_reply.started":"2022-11-29T09:45:51.121709Z","shell.execute_reply":"2022-11-29T09:46:14.101377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from detectron2.evaluation import COCOEvaluator, inference_on_dataset\nfrom detectron2.data import build_detection_test_loader\n\n# Evaluate model\nevaluator_C4 = COCOEvaluator(\"mat_val\", output_dir=\"./output\")\nval_loader_C4 = build_detection_test_loader(cfg_C4, \"mat_val\")\nresult_C4 = inference_on_dataset(predictor_C4.model, val_loader_C4, evaluator_C4)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T09:47:00.277444Z","iopub.execute_input":"2022-11-29T09:47:00.277847Z","iopub.status.idle":"2022-11-29T09:49:20.413739Z","shell.execute_reply.started":"2022-11-29T09:47:00.277791Z","shell.execute_reply":"2022-11-29T09:49:20.412814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_C4","metadata":{"execution":{"iopub.status.busy":"2022-11-29T09:50:07.740395Z","iopub.execute_input":"2022-11-29T09:50:07.740777Z","iopub.status.idle":"2022-11-29T09:50:07.750754Z","shell.execute_reply.started":"2022-11-29T09:50:07.740737Z","shell.execute_reply":"2022-11-29T09:50:07.749679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_C4 = collections.OrderedDict([('bbox',\n              {'AP': 4.467343707791655,\n               'AP50': 8.741681144504621,\n               'AP75': 4.467835182009489,\n               'APs': 2.4755099795693853,\n               'APm': 3.8200423974295807,\n               'APl': 5.0936944011820575,\n               'AP-shirt, blouse': 0.0,\n               'AP-top, t-shirt, sweatshirt': 9.964190649549916,\n               'AP-sweater': 0.0,\n               'AP-cardigan': 0.0,\n               'AP-jacket': 0.0,\n               'AP-vest': 0.0,\n               'AP-pants': 28.897438521569303,\n               'AP-shorts': 0.0,\n               'AP-skirt': 6.9306930693069315,\n               'AP-coat': 0.0,\n               'AP-dress': 33.31648666484868,\n               'AP-jumpsuit': 0.0,\n               'AP-cape': 0.0,\n               'AP-glasses': 0.0,\n               'AP-hat': 0.0,\n               'AP-headband, head covering, hair accessory': 0.0,\n               'AP-tie': 0.0,\n               'AP-glove': 0.0,\n               'AP-watch': 0.0,\n               'AP-belt': 0.0,\n               'AP-leg warmer': -1,\n               'AP-tights, stockings': 0.0,\n               'AP-sock': 0.0,\n               'AP-shoe': 30.470569136050194,\n               'AP-bag, wallet': 4.752475247524752,\n               'AP-scarf': 0.0,\n               'AP-umbrella': -1,\n               'AP-hood': 0.0,\n               'AP-collar': 0.0,\n               'AP-lapel': 6.188904604746188,\n               'AP-epaulette': 0.0,\n               'AP-sleeve': 41.37866770291117,\n               'AP-pocket': 0.0,\n               'AP-neckline': 12.32697900736742,\n               'AP-buckle': 0.0,\n               'AP-zipper': 0.0,\n               'AP-applique': 0.0,\n               'AP-bead': 0.0,\n               'AP-bow': 0.0,\n               'AP-flower': -1,\n               'AP-fringe': -1,\n               'AP-ribbon': -1,\n               'AP-rivet': 0.0,\n               'AP-ruffle': 0.0,\n               'AP-sequin': -1,\n               'AP-tassel': -1}),\n             ('segm',\n              {'AP': 3.944894844933721,\n               'AP50': 6.668759092165412,\n               'AP75': 4.179548972045359,\n               'APs': 0.25586189388169583,\n               'APm': 1.9828757378409902,\n               'APl': 4.711149322337242,\n               'AP-shirt, blouse': 0.0,\n               'AP-top, t-shirt, sweatshirt': 13.345997577369797,\n               'AP-sweater': 0.0,\n               'AP-cardigan': 0.0,\n               'AP-jacket': 0.0,\n               'AP-vest': 0.0,\n               'AP-pants': 31.943161622461858,\n               'AP-shorts': 0.0,\n               'AP-skirt': 8.91089108910891,\n               'AP-coat': 0.0,\n               'AP-dress': 36.07056174690547,\n               'AP-jumpsuit': 0.0,\n               'AP-cape': 0.0,\n               'AP-glasses': 0.0,\n               'AP-hat': 0.0,\n               'AP-headband, head covering, hair accessory': 0.0,\n               'AP-tie': 0.0,\n               'AP-glove': 0.0,\n               'AP-watch': 0.0,\n               'AP-belt': 0.0,\n               'AP-leg warmer': -1,\n               'AP-tights, stockings': 0.0,\n               'AP-sock': 0.0,\n               'AP-shoe': 15.510367816578915,\n               'AP-bag, wallet': 4.158415841584159,\n               'AP-scarf': 0.0,\n               'AP-umbrella': -1,\n               'AP-hood': 0.0,\n               'AP-collar': 0.0,\n               'AP-lapel': 0.0,\n               'AP-epaulette': 0.0,\n               'AP-sleeve': 43.88888280120257,\n               'AP-pocket': 0.0,\n               'AP-neckline': 0.022620457203460627,\n               'AP-buckle': 0.0,\n               'AP-zipper': 0.0,\n               'AP-applique': 0.0,\n               'AP-bead': 0.0,\n               'AP-bow': 0.0,\n               'AP-flower': -1,\n               'AP-fringe': -1,\n               'AP-ribbon': -1,\n               'AP-rivet': 0.0,\n               'AP-ruffle': 0.0,\n               'AP-sequin': -1,\n               'AP-tassel': -1})])","metadata":{"execution":{"iopub.status.busy":"2022-11-29T10:03:36.682829Z","iopub.execute_input":"2022-11-29T10:03:36.683317Z","iopub.status.idle":"2022-11-29T10:03:36.711978Z","shell.execute_reply.started":"2022-11-29T10:03:36.683269Z","shell.execute_reply":"2022-11-29T10:03:36.706857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"results_dict = {}\n\n# Create table to compare results\nresults_dict['bbox_DC5'] = result_DC5['bbox']\nresults_dict['bbox_C4'] = result_C4['bbox']\n#results_dict['bbox_FPN'] = result_FPN['bbox']\nresults_dict['segm_DC5'] = result_DC5['segm']\nresults_dict['segm_C4'] = result_C4['segm']\n#results_dict['segm_FPN'] = result_FPN['segm']\n\ndf_results = pd.DataFrame.from_dict(results_dict)\ndf_results.loc[['AP', 'AP50', 'AP75', 'APs', 'APm', 'APl']]","metadata":{"execution":{"iopub.status.busy":"2022-11-29T10:00:50.482757Z","iopub.execute_input":"2022-11-29T10:00:50.483792Z","iopub.status.idle":"2022-11-29T10:00:50.499076Z","shell.execute_reply.started":"2022-11-29T10:00:50.483750Z","shell.execute_reply":"2022-11-29T10:00:50.497828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import ast\n\nmetrics = {}\n\n# Create losses plots\n#for folder in [\"FPN\", \"C4\", \"DC5\"]:\nfor folder in [\"C4\", \"DC5\"]:\n    with open(f'output_{folder}/metrics.json') as file:\n        lines = file.readlines()\n    \n    metrics_model = []\n    for line in lines:\n        metrics_model.append(ast.literal_eval(line))\n    metrics[folder] = metrics_model","metadata":{"execution":{"iopub.status.busy":"2022-11-29T10:03:58.154580Z","iopub.execute_input":"2022-11-29T10:03:58.154963Z","iopub.status.idle":"2022-11-29T10:03:58.185958Z","shell.execute_reply.started":"2022-11-29T10:03:58.154928Z","shell.execute_reply":"2022-11-29T10:03:58.184751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfig, axs = plt.subplots(3, 4, figsize=(20,10))\n\n#for idx, model in enumerate([\"FPN\", \"C4\", \"DC5\"]):\nfor idx, model in enumerate([\"C4\", \"DC5\"]):\n    met = metrics[model]\n    for loss_id, loss in enumerate([\"loss_box_reg\", \"loss_mask\", \"loss_cls\", \"total_loss\"]):\n        ax = axs[idx, loss_id]\n        total_loss = [loss_dict[loss] for loss_dict in met]\n        iterations = [loss_dict['iteration'] for loss_dict in met]\n\n        ax.set_title(f\"{model} - {loss}\")\n        ax.set_xlabel(\"iterations\")\n        ax.plot(iterations, total_loss)\n        ax.grid()\n        \nfig.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-11-29T09:54:47.180577Z","iopub.execute_input":"2022-11-29T09:54:47.180955Z","iopub.status.idle":"2022-11-29T09:54:48.673393Z","shell.execute_reply.started":"2022-11-29T09:54:47.180923Z","shell.execute_reply":"2022-11-29T09:54:48.669794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.chdir(r'/kaggle/working/output_C4')\n\nfrom IPython.display import FileLink\n\nFileLink(r'metrics.json')","metadata":{"execution":{"iopub.status.busy":"2022-11-29T10:12:35.822152Z","iopub.execute_input":"2022-11-29T10:12:35.822547Z","iopub.status.idle":"2022-11-29T10:12:35.847234Z","shell.execute_reply.started":"2022-11-29T10:12:35.822508Z","shell.execute_reply":"2022-11-29T10:12:35.846222Z"},"trusted":true},"execution_count":null,"outputs":[]}]}